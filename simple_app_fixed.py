# COMPLETE ALL-IN-ONE STREAMLIT APP
# Save this as: neuro_match_complete.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
from datetime import datetime
import tempfile
import os
import sys

# ========== CONFIGURATION ==========
st.set_page_config(
    page_title="NeuroMatch AI - Ultimate HR Platform",
    page_icon="ðŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== PREMIUM CSS ==========
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Plus+Jakarta+Sans:wght@700;800&display=swap');
    
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        font-family: 'Inter', sans-serif;
    }
    
    .main .block-container {
        background: white;
        border-radius: 20px;
        padding: 3rem 2rem;
        margin: 2rem auto;
        max-width: 1200px;
        box-shadow: 0 20px 40px rgba(0,0,0,0.1);
    }
    
    .premium-header {
        font-family: 'Plus Jakarta Sans', sans-serif;
        font-size: 3.5rem;
        font-weight: 800;
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }
    
    .feature-card {
        background: #f8fafc;
        border-radius: 15px;
        padding: 2rem;
        margin: 1rem 0;
        border-left: 4px solid #667eea;
        transition: transform 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: 600;
    }
    
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ========== CORE FUNCTIONS ==========
def parse_resume_professional(text):
    """Parse resume text and extract key information"""
    name = extract_candidate_name(text)
    
    # Extract experience
    exp_patterns = [r'(\d+)\+?\s*years?\s*(?:of\s*)?experience', r'(\d+)\+?\s*yrs?\s*experience']
    experience = 0
    for pattern in exp_patterns:
        matches = re.findall(pattern, text.lower())
        if matches:
            experience = max([int(match) for match in matches])
            break
    
    # Extract skills
    skill_keywords = ['python', 'java', 'javascript', 'react', 'sql', 'aws', 'docker', 'machine learning', 'ai']
    skills = [skill for skill in skill_keywords if skill in text.lower()]
    
    return {
        'name': name,
        'experience': experience,
        'skills': skills,
        'text': text
    }

def extract_candidate_name(text):
    """Extract candidate name from resume"""
    lines = text.strip().split('\n')
    for line in lines[:3]:
        line = line.strip()
        if line and len(line.split()) <= 4 and len(line) > 3:
            if not any(keyword in line.lower() for keyword in ['email', 'phone', 'address']):
                return line
    return "Candidate"

def calculate_match_score(resume_data, job_requirements):
    """Calculate professional match score"""
    skills_match = len(set(resume_data['skills']) & set(job_requirements.get('skills', []))) / max(len(job_requirements.get('skills', [])), 1)
    exp_match = min(resume_data['experience'] / max(job_requirements.get('min_experience', 1), 1), 1.0)
    
    final_score = (skills_match * 0.6 + exp_match * 0.4)
    
    if final_score >= 0.8:
        status = "SELECTED"
    elif final_score >= 0.6:
        status = "SHORTLISTED"
    else:
        status = "REVIEW"
    
    return {
        'score': final_score,
        'status': status,
        'skills_match': skills_match,
        'exp_match': exp_match
    }

def generate_interview_questions(resume_data):
    """Generate personalized interview questions"""
    questions = []
    
    if resume_data['experience'] > 0:
        questions.append(f"Tell me about your {resume_data['experience']} years of experience")
    
    for skill in resume_data['skills'][:3]:
        questions.append(f"Describe a project where you used {skill}")
    
    questions.extend([
        "How do you handle tight deadlines?",
        "Describe a challenging problem you solved",
        "Where do you see yourself in 5 years?"
    ])
    
    return questions[:6]

# ========== STREAMLIT PAGES ==========
def home_page():
    st.markdown('<h1 class="premium-header">NEUROMATCH AI</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666;">Intelligent Resume Analysis Platform</p>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="feature-card">
            <h3>ðŸ§  AI Analysis</h3>
            <p>Advanced resume parsing with machine learning algorithms</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="feature-card">
            <h3>âš¡ Instant Results</h3>
            <p>Get comprehensive candidate analysis in seconds</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="feature-card">
            <h3>ðŸ“Š Smart Ranking</h3>
            <p>Automated candidate ranking based on job requirements</p>
        </div>
        """, unsafe_allow_html=True)

def single_analysis_page():
    st.markdown("## ðŸ”¬ Single Resume Analysis")
    
    # Input method
    input_method = st.radio("Choose input method:", ["Upload PDF", "Paste Text"], horizontal=True)
    
    resume_text = ""
    
    if input_method == "Upload PDF":
        uploaded_file = st.file_uploader("Upload PDF Resume", type=['pdf'])
        if uploaded_file:
            # Simple text extraction (you can enhance this)
            st.success(f"File uploaded: {uploaded_file.name}")
            resume_text = "Sample resume text - Add proper PDF parsing here"
    else:
        resume_text = st.text_area("Paste resume text:", height=200)
    
    if resume_text:
        st.markdown("### ðŸŽ¯ Job Requirements")
        col1, col2 = st.columns(2)
        
        with col1:
            required_skills = st.text_input("Required Skills (comma separated)", "python, sql, machine learning")
            min_experience = st.slider("Minimum Experience", 0, 10, 2)
        
        with col2:
            job_title = st.text_input("Job Title", "Data Scientist")
        
        if st.button("Analyze Resume", type="primary"):
            with st.spinner("Analyzing..."):
                resume_data = parse_resume_professional(resume_text)
                job_req = {
                    'skills': [s.strip().lower() for s in required_skills.split(',')],
                    'min_experience': min_experience
                }
                
                result = calculate_match_score(resume_data, job_req)
                
                # Display results
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Match Score", f"{result['score']:.1%}")
                with col2:
                    st.metric("Status", result['status'])
                with col3:
                    st.metric("Experience", f"{resume_data['experience']} years")
                
                # Interview questions
                st.markdown("### ðŸ¤– AI Interview Questions")
                questions = generate_interview_questions(resume_data)
                for i, q in enumerate(questions, 1):
                    st.write(f"{i}. {q}")

def bulk_analysis_page():
    st.markdown("## ðŸš€ Bulk Resume Processing")
    
    input_method = st.radio("Input method:", ["Upload Multiple PDFs", "Paste Multiple Resumes"], horizontal=True)
    
    if input_method == "Upload Multiple PDFs":
        uploaded_files = st.file_uploader("Upload PDFs", type=['pdf'], accept_multiple_files=True)
        if uploaded_files:
            st.success(f"{len(uploaded_files)} files uploaded")
    else:
        bulk_text = st.text_area("Paste resumes (separate with ---RESUME---)", height=300)
        if bulk_text:
            resumes = [r.strip() for r in bulk_text.split("---RESUME---") if r.strip()]
            st.success(f"{len(resumes)} resumes detected")
    
    if st.button("Process Bulk Analysis", type="primary"):
        # Simulate results
        results = [
            {'name': 'Sarah Chen', 'score': 0.92, 'status': 'SELECTED', 'exp': 5},
            {'name': 'Mike Johnson', 'score': 0.78, 'status': 'SHORTLISTED', 'exp': 3},
            {'name': 'Lisa Wang', 'score': 0.65, 'status': 'REVIEW', 'exp': 2}
        ]
        
        st.markdown("### ðŸ“Š Results")
        for result in results:
            st.write(f"**{result['name']}** - Score: {result['score']:.1%} - {result['status']}")

# ========== MAIN APP ==========
def main():
    st.sidebar.title("ðŸš€ Navigation")
    page = st.sidebar.selectbox("Choose Page", ["Home", "Single Analysis", "Bulk Analysis"])
    
    if page == "Home":
        home_page()
    elif page == "Single Analysis":
        single_analysis_page()
    elif page == "Bulk Analysis":
        bulk_analysis_page()

if __name__ == "__main__":
    main()