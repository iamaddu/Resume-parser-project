from flask import Flask, render_template, request, redirect, url_for, flash, session
import os
from resume_parser import extract_text_from_pdf, parse_resume, is_resume_pdf, detect_ai_generated
from ranker import create_feature_vector, rule_based_score, train_dummy_model
import pandas as pd
import io
from flask import send_file, request
import json

app = Flask(__name__)
app.secret_key = "supersecretkey"
UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# Train dummy ML model at startup (for demonstration)
ml_model, ml_keywords = train_dummy_model()

def detect_ai_generated(text: str) -> bool:
    """
    Basic heuristic to detect likely AI-generated text in a resume.
    This is intentionally simple for demonstration: it checks for known
    AI markers and a couple of naive heuristics.
    """
    if not text:
        return False
    t = text.lower()

    # Known explicit markers
    ai_indicators = [
        "generated by",
        "chatgpt",
        "gpt-",
        "openai",
        "this resume was",
        "as an ai"
    ]
    for ind in ai_indicators:
        if ind in t:
            return True

    # Heuristic: repeated consecutive words (common in generated text faults)
    words = t.split()
    for i in range(len(words) - 2):
        if words[i] == words[i+1] == words[i+2]:
            return True

    # Heuristic: very high ratio of stop punctuation to content (quick check)
    if t.count('.') + t.count('!') + t.count('?') > 0 and len(t) / (t.count('.') + t.count('!') + t.count('?')) < 20:
        return True

    return False

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    if 'resume' not in request.files:
        flash('No file part')
        return redirect(url_for('index'))
    file = request.files['resume']
    if file.filename == '':
        flash('No selected file')
        return redirect(url_for('index'))
    if not file.filename.lower().endswith('.pdf'):
        flash('Only PDF files are supported.')
        return redirect(url_for('index'))

    # Save uploaded file
    save_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
    file.save(save_path)

    # Extract text and parse resume
    try:
        text = extract_text_from_pdf(save_path)
        resume_data = parse_resume(text)
    except Exception as e:
        flash(f"Error processing PDF: {e}")
        return redirect(url_for('index'))

    if not is_resume_pdf(text):
        flash("Uploaded PDF does not appear to be a resume. Please upload a valid resume PDF.")
        return redirect(url_for('index'))

    # Get job keywords from form
    keywords_raw = request.form.get('keywords', '')
    job_keywords = [kw.strip().lower() for kw in keywords_raw.split(',') if kw.strip()]

    # Feature vector and scoring
    feature_vector = create_feature_vector(resume_data, job_keywords)
    rule_score = rule_based_score(resume_data, job_keywords)

    # ML model prediction (for demonstration)
    ml_score = None
    if feature_vector.shape[0] == len(ml_keywords) + 1 + 6:  # skills + exp + edu
        ml_score = ml_model.predict_proba([feature_vector])[0][1] * 100

    return render_template(
        'results.html',
        resume_data=resume_data,
        rule_score=rule_score,
        ml_score=ml_score,
        job_keywords=job_keywords
    )

# (Optional) API endpoint for AI-Resume Evaluation
@app.route('/api/evaluate', methods=['POST'])
def api_evaluate():
    data = request.json
    text = data.get('resume_text', '')
    job_keywords = data.get('job_keywords', [])
    resume_data = parse_resume(text)
    feature_vector = create_feature_vector(resume_data, job_keywords)
    rule_score = rule_based_score(resume_data, job_keywords)
    return {
        "resume_data": resume_data,
        "rule_score": rule_score
    }

@app.route('/bulk_upload', methods=['GET', 'POST'])
def bulk_upload():
    results = []
    if request.method == 'POST':
        file = request.files.get('csvfile')
        keywords_raw = request.form.get('keywords', '')
        job_keywords = [kw.strip().lower() for kw in keywords_raw.split(',') if kw.strip()]
        if file and file.filename.endswith('.csv'):
            df = pd.read_csv(file)
            for idx, row in df.iterrows():
                text = row.get('resume_text', '')
                resume_data = parse_resume(text)
                feature_vector = create_feature_vector(resume_data, job_keywords)
                rule_score = rule_based_score(resume_data, job_keywords)
                results.append({
                    "name": row.get('name', f"Resume {idx+1}"),
                    "skills": ", ".join(resume_data['skills']),
                    "experience": resume_data['experience'],
                    "education": "; ".join(resume_data['education']),
                    "score": rule_score
                })
    return render_template('bulk_results.html', results=results)

@app.route('/download_results', methods=['POST'])
def download_results():
    results_json = request.form.get('results', '[]')
    results = json.loads(results_json)
    df = pd.DataFrame(results)
    output = io.StringIO()
    df.to_csv(output, index=False)
    output.seek(0)
    return send_file(
        io.BytesIO(output.getvalue().encode()),
        mimetype='text/csv',
        as_attachment=True,
        download_name='resume_results.csv'
    )

@app.route('/bulk_pdf_upload', methods=['POST'])
def bulk_pdf_upload():
    files = request.files.getlist('resumes')
    keywords_raw = request.form.get('keywords', '')
    top_n = int(request.form.get('top_n', 3))
    job_keywords = [kw.strip().lower() for kw in keywords_raw.split(',') if kw.strip()]
    results = []

    for file in files:
        if file and file.filename.lower().endswith('.pdf'):
            save_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(save_path)
            try:
                text = extract_text_from_pdf(save_path)
                if not is_resume_pdf(text):
                    results.append({
                        "filename": file.filename,
                        "skills": "",
                        "experience": "",
                        "education": "",
                        "score": 0,
                        "ai_generated": "",
                        "explanation": "Rejected: Not a resume PDF.",
                        "error": "Not a resume PDF"
                    })
                    continue
                resume_data = parse_resume(text)
                feature_vector = create_feature_vector(resume_data, job_keywords)
                rule_score = rule_based_score(resume_data, job_keywords)
                is_ai = "Yes" if detect_ai_generated(text) else "No"
                explanation = explain_resume(resume_data, job_keywords)
                results.append({
                    "filename": file.filename,
                    "name": resume_data.get("name", ""),
                    "email": resume_data.get("email", ""),
                    "phone": resume_data.get("phone", ""),
                    "skills": ", ".join(resume_data['skills']),
                    "experience": resume_data['experience'],
                    "education": "; ".join(resume_data['education']),
                    "score": rule_score,
                    "ai_generated": is_ai,
                    "explanation": explanation,
                    "error": ""
                })
            except Exception as e:
                results.append({
                    "filename": file.filename,
                    "skills": "",
                    "experience": "",
                    "education": "",
                    "score": 0,
                    "ai_generated": "",
                    "explanation": "",
                    "error": str(e)
                })
        else:
            results.append({
                "filename": file.filename,
                "skills": "",
                "experience": "",
                "education": "",
                "score": 0,
                "ai_generated": "",
                "explanation": "",
                "error": "Not a resume PDF"
            })

    # Sort results by score descending
    results = sorted(results, key=lambda x: x['score'], reverse=True)

    MIN_SCORE = 1.0  # Minimum score to be considered for selection

    selected_count = 0
    for idx, r in enumerate(results):
        has_skill = r['skills'].strip() != ""
        if selected_count < top_n and r['score'] >= MIN_SCORE and has_skill:
            r['selected'] = True
            r['selection_reason'] = f"Selected: Score in top {top_n} ({r['score']}%). {r['explanation']}"
            selected_count += 1
        else:
            r['selected'] = False
            reason = "Not selected: "
            if r['score'] < MIN_SCORE:
                reason += f"Score too low ({r['score']}%). "
            if not has_skill:
                reason += "No key skills matched. "
            reason += r['explanation']
            r['selection_reason'] = reason

    best_resume = results[0] if results else None

    return render_template('bulk_results.html', results=results, best_resume=best_resume, top_n=top_n)

def explain_resume(resume_data, job_keywords):
    # small helper to normalize skill strings for matching
    def normalize_skill(s):
        if not s:
            return ""
        s = s.lower().strip()
        import re
        s = re.sub(r'[^a-z0-9\s]+', ' ', s)
        s = re.sub(r'\s+', ' ', s).strip()
        return s

    # Normalize job keywords for matching
    normalized_keywords = [normalize_skill(kw) for kw in job_keywords]
    skills_list = resume_data.get("skills", []) or []
    normalized_skills = [normalize_skill(s) for s in skills_list]
    matched_skills = [kw for kw in normalized_keywords if kw in normalized_skills]

    explanation = f"Matched skills: {', '.join(matched_skills)}" if matched_skills else "No key skills matched"
    exp = resume_data.get('experience')
    if exp:
        explanation += f"; Experience: {exp} years"
    edu = resume_data.get('education')
    if edu:
        explanation += f"; Education: {', '.join(edu)}"
    email = resume_data.get('email')
    if email:
        explanation += f"; Contact: {email}"
    return explanation

ADMIN_USERNAME = "HARSHITHA"
ADMIN_PASSWORD = "123456"  # Change this to a strong password!

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        username = request.form.get('username', '')
        password = request.form.get('password', '')
        if username == ADMIN_USERNAME and password == ADMIN_PASSWORD:
            session['logged_in'] = True
            return redirect(url_for('index'))
        else:
            flash('Invalid credentials')
    return render_template('login.html')

@app.route('/logout')
def logout():
    session.pop('logged_in', None)
    flash('Logged out successfully')
    return redirect(url_for('login'))

# Protect all main routes
@app.before_request
def require_login():
    allowed_routes = [
        'login', 'static', 'index', 'upload', 'bulk_upload', 'bulk_pdf_upload',
        'download_results', 'logout', 'api_evaluate'
    ]
    if request.endpoint not in allowed_routes and not session.get('logged_in'):
        return redirect(url_for('login'))

if __name__ == "__main__":
    app.run(debug=True)